{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c71dae-9e3e-4859-87ee-8545b8aae701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mne\n",
      "  Downloading mne-1.10.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: decorator in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from mne) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from mne) (3.1.6)\n",
      "Collecting lazy-loader>=0.3 (from mne)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: matplotlib>=3.7 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from mne) (3.10.7)\n",
      "Requirement already satisfied: numpy<3,>=1.25 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from mne) (2.3.4)\n",
      "Requirement already satisfied: packaging in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from mne) (25.0)\n",
      "Collecting pooch>=1.5 (from mne)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: scipy>=1.11 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from mne) (1.16.2)\n",
      "Collecting tqdm (from mne)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from matplotlib>=3.7->mne) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from matplotlib>=3.7->mne) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from matplotlib>=3.7->mne) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from pooch>=1.5->mne) (4.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from pooch>=1.5->mne) (2.32.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from jinja2->mne) (3.0.3)\n",
      "Requirement already satisfied: colorama in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from tqdm->mne) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.10.5)\n",
      "Downloading mne-1.10.2-py3-none-any.whl (7.4 MB)\n",
      "   ---------------------------------------- 0.0/7.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/7.4 MB 2.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/7.4 MB 2.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.6/7.4 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.4/7.4 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.9/7.4 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.4/7.4 MB 2.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.9/7.4 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.7/7.4 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.2/7.4 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.8/7.4 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.3/7.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.8/7.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.3/7.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.4/7.4 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, lazy-loader, pooch, mne\n",
      "Successfully installed lazy-loader-0.4 mne-1.10.2 pooch-1.8.2 tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "119e7d35-4643-4c42-8c41-d7bc039c97ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (25.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.8 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.0.1\n",
      "    Uninstalling pip-25.0.1:\n",
      "      Successfully uninstalled pip-25.0.1\n",
      "Successfully installed pip-25.2\n"
     ]
    }
   ],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d69dec17-6d4e-4056-a89b-44cdf48e4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne # MNE is a standard library for EEG data analysis\n",
    "import os # to interact with the computer operating system (handling files, directories and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fbf8fda-d668-486f-9d89-24b00629873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.13-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from kagglehub) (6.0.3)\n",
      "Requirement already satisfied: requests in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from kagglehub) (2.32.5)\n",
      "Requirement already satisfied: tqdm in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from requests->kagglehub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from requests->kagglehub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from requests->kagglehub) (2025.10.5)\n",
      "Requirement already satisfied: colorama in d:\\final year project\\machine learning models\\fyp-ml-models\\deap dataset\\venv\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.13-py3-none-any.whl (68 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce8ce560-8602-4315-b714-164e71743c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Sameera\\.cache\\kagglehub\\datasets\\manh123df\\deap-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Download the DEAP dataset from kaggle\n",
    "\n",
    "import kagglehub\n",
    "import pickle\n",
    "\n",
    "# latest version\n",
    "\n",
    "path = r\"C:\\Users\\Sameera\\.cache\\kagglehub\\datasets\\manh123df\\deap-dataset\\versions\\1\"\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eac9c172-b721-458d-b288-588f6ee692b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for files in: C:\\Users\\Sameera\\.cache\\kagglehub\\datasets\\manh123df\\deap-dataset\\versions\\1\\deap-dataset\\data_preprocessed_python\n",
      "First subject file expected: C:\\Users\\Sameera\\.cache\\kagglehub\\datasets\\manh123df\\deap-dataset\\versions\\1\\deap-dataset\\data_preprocessed_python\\s01.dat\n"
     ]
    }
   ],
   "source": [
    "# The 'path' variable from download (kaggle)\n",
    "# navigate to the directory containing the subject files\n",
    "DEAP_DATA_PATH = os.path.join(path, r\"deap-dataset\\data_preprocessed_python\")\n",
    "\n",
    "#List of subjects\n",
    "subject_ids = [f's{i:02d}' for i in range(1,33)]\n",
    "\n",
    "# verify the path\n",
    "print(f\"Looking for files in: {DEAP_DATA_PATH}\")\n",
    "print(f\"First subject file expected: {os.path.join(DEAP_DATA_PATH, subject_ids[0] + '.dat')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "770f4615-f93a-4b9e-b9f5-7a487dc186aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 0-indexed positions of the 14 selected EEG channels in the DEAP file structure (0-31)\n",
    "\n",
    "selected_indices = [0, 1, 2, 3, 6, 10, 12, 16, 17, 19, 20, 24, 28, 30]\n",
    "\n",
    "def select_channels(eeg_data, indices):\n",
    "    #eeg_data shape in (trials, total_channles, time_points) -> (40,40,8064) in raw DEAP\n",
    "    #assume the EEG channels are the first 32\n",
    "    eeg_32_channels = eeg_data[:, 0:32, :]\n",
    "\n",
    "    #selects only the 14 desired EEG channels\n",
    "    return eeg_32_channels[:, indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4804f751-5097-465f-968c-4400bf04a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing s01...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'zeroes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m high_arousal = (arousal >= \u001b[32m4.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Creates the 4-class one-hot labels\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m labels_one_hot = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeroes\u001b[49m((\u001b[32m40\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# LALV : Low Arousal Low Valence -> [1, 0, 0, 0]\u001b[39;00m\n\u001b[32m     38\u001b[39m labels_one_hot[(high_arousal == \u001b[32m0\u001b[39m) & (high_valence == \u001b[32m0\u001b[39m), \u001b[32m0\u001b[39m] = \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Final Year Project\\Machine Learning models\\FYP-ML-Models\\DEAP dataset\\venv\\Lib\\site-packages\\numpy\\__init__.py:808\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr)\u001b[39m\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchar\u001b[39;00m\n\u001b[32m    806\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m char.chararray\n\u001b[32m--> \u001b[39m\u001b[32m808\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'numpy' has no attribute 'zeroes'"
     ]
    }
   ],
   "source": [
    "all_raw_data = []\n",
    "all_labels = []\n",
    "\n",
    "def load_subject_data(subject_id):\n",
    "    file_path = os.path.join(DEAP_DATA_PATH, subject_id + '.dat')\n",
    "\n",
    "    # The 'latin1' encoding is necessary for loading DEAP dataset files\n",
    "    with open(file_path, 'rb') as f:\n",
    "        subject_data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "    return subject_data\n",
    "\n",
    "for subject_id in subject_ids:\n",
    "    print(f\"Processing {subject_id}...\")\n",
    "\n",
    "    subject_data = load_subject_data(subject_id)\n",
    "\n",
    "    # Get the raw EEG data: shape (40 trials, 40 channels, 8064 time points)\n",
    "    eeg_data = subject_data['data']\n",
    "\n",
    "    # STEP 1: Channel Selection (14 Channels)\n",
    "    data_14_channels = select_channels(eeg_data, selected_indices)\n",
    "\n",
    "    # STEP 2: Label Discretization and One-Hot Encoding\n",
    "    # Labels array has shape (40, 4) -> [Valence, Arousal, Dominance, Liking]\n",
    "    labels_raw = subject_data['labels']\n",
    "    valence = labels_raw[:, 0]\n",
    "    arousal = labels_raw[:, 1]\n",
    "\n",
    "    # Threshold for High/Low is >= 4.5 (paper 2)\n",
    "    high_valence = (valence >= 4.5).astype(int)\n",
    "    high_arousal = (arousal >= 4.5).astype(int)\n",
    "\n",
    "    # Creates the 4-class one-hot labels\n",
    "    labels_one_hot = np.zeroes((40, 4))\n",
    "\n",
    "    # LALV : Low Arousal Low Valence -> [1, 0, 0, 0]\n",
    "    labels_one_hot[(high_arousal == 0) & (high_valence == 0), 0] = 1\n",
    "    # HALV : High Arousal Low Valence -> [0, 1, 0, 0]\n",
    "    labels_one_hot[(high_arousal == 1) & (high_valence == 0), 1] = 1\n",
    "    # LAHV : Low Arousal High Valence -> [0, 0, 1, 0]\n",
    "    labels_one_hot[(high_arousal == 0) & (high_valence == 1), 2] = 1\n",
    "    # HAHV : High Arousal High Valence -> [0, 0, 0, 1]\n",
    "\n",
    "    all_raw_data.append(data_14_channels)\n",
    "    all_labels.append(labels_one_hot)\n",
    "\n",
    "\n",
    "# Final Conatenation (Accross all 32 subjects)\n",
    "X_raw = np.concatenate(all_raw_data, axis=0)\n",
    "Y_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "print(\"\\n--- Final RAW Dataset Summary ---\")\n",
    "print(f\"Total RAW Data shape (Epochs, Channels, Time Points): {X_raw.shape}\")\n",
    "print(f\"Total Labels shape (Epochs, 4 Classes): {Y_labels.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
